---
presentation:
  margin: 0
  center: false
  transition: "convex"
  enableSpeakerNotes: true
  slideNumber: "c/t"
  navigationMode: "linear"
---

@import "../css/font-awesome-4.7.0/css/font-awesome.css"
@import "../css/theme/solarized.css"
@import "../css/logo.css"
@import "../css/font.css"
@import "../css/color.css"
@import "../css/margin.css"
@import "../css/table.css"
@import "../css/main.css"
@import "../plugin/zoom/zoom.js"
@import "../plugin/customcontrols/plugin.js"
@import "../plugin/customcontrols/style.css"
@import "../plugin/chalkboard/plugin.js"
@import "../plugin/chalkboard/style.css"
@import "../plugin/menu/menu.js"
@import "../js/anychart/anychart-core.min.js"
@import "../js/anychart/anychart-venn.min.js"
@import "../js/anychart/pastel.min.js"
@import "../js/anychart/venn-ml.js"
@import "https://cdn.bootcdn.net/ajax/libs/jquery/3.5.0/jquery.js"

<!-- slide data-notes="" -->

<div class="bottom20"></div>

# 机器学习

<hr class="width50 center">

## k-近邻法

<div class="bottom8"></div>

### 计算机学院 &nbsp;&nbsp; 张腾

#### _tengzhang@hust.edu.cn_

<!-- slide vertical=true data-notes="" -->

##### 大纲

---

@import "../vega/outline.json" {as="vega" .top-2}

<!-- slide data-notes="" -->

##### <span style="font-weight:900">1-</span>近邻算法

---

基本假设：{==相似的样本属于相同的类别==}

- 样本空间$\Xcal \subseteq \Rbb^d$，类别标记集合$\Ycal = [c]$
- $\Dcal$是$\Xcal \times \Ycal$上的未知概率分布，概率密度函数为$\Pbb(\xv, y)$
- 距离度量：$\dist: \Xcal \times \Xcal \mapsto \Rbb^+$，非负、对称、三角不等式

<div class="top3"></div>

输入：$D = \{ (\xv_i, y_i) \}_{i \in [m]} \in (\Xcal \times \Ycal)^m$，待预测样本$\xv$

<div class="top-3"></div>

输出：$\xv$的类别$y$

1. 根据选定的距离度量，记$D$中与$\xv$最近的样本为$\xvhat$
2. 输出$\yhat$

<div class="top4"></div>

我的批注 近邻法没有显式的学习过程

<!-- slide vertical=true data-notes="" -->

##### <span style="font-weight:900">1-</span>近邻算法 空间划分

---

@import "../tikz/knn.svg" {.center .width50 .top5}

<!-- slide data-notes="" -->

##### <span style="font-weight:900">1-</span>近邻算法 理论分析

---

设贝叶斯最优分类器$h^\star(\xv) = \mathop{\arg\max}_{y \in \Ycal} \Pbb(y|\xv)$的错误率为$R^\star$

$$
\begin{align*}
    \quad R^\star = \int \underbrace{(1 - \Pbb(h^\star(\xv) | \xv))}_{h^\star(\xv)\text{出错的概率}\qquad} \Pbb(\xv) \diff \xv = \int \Pbb (e^\star | \xv) \Pbb(\xv) \diff \xv
\end{align*}
$$

<div class="top-2"></div>

设1-近邻算法的错误率为$R_m$，其中下标$m$表示样本数，则

$$
\begin{align*}
    \quad R^\star \le R = \lim_{m \rightarrow \infty} R_m \le R^\star \left( 2 - \frac{c}{c-1} R^\star \right) \overset{c=2}{=} 2 R^\star (1 - R^\star)
\end{align*}
$$

对二分类问题，易知当$R^\star \in \{ 0, 1/2 \}$时，界是紧的

下界是显然的，下面考虑上界

<!-- slide vertical=true data-notes="" -->

##### <span style="font-weight:900">1-</span>近邻算法 理论分析

---

设1-近邻算法的错误率为$R_m$，其中下标$m$表示样本数，则

$$
\begin{align*}
    \quad R^\star & = \int \underbrace{(1 - \Pbb(h^\star(\xv) | \xv))}_{h^\star(\xv)\text{出错的概率}\qquad} \Pbb(\xv) \diff \xv = \int \Pbb (e^\star | \xv) \Pbb(\xv) \diff \xv \\
    R^\star & \le R = \lim_{m \rightarrow \infty} R_m \le R^\star \left( 2 - \frac{c}{c-1} R^\star \right) \overset{c=2}{=} 2 R^\star (1 - R^\star)
\end{align*}
$$

<div class="top-2"></div>

预测出错的概率为$\Pbb(e|\xv) = 1 - \sum_{j \in [c]} \Pbb(y=j|\xv) \Pbb(\yhat=j|\xvhat)$，当$m \rightarrow \infty$时有$\xvhat \rightarrow \xv$，从而$\Pbb(e|\xv) = 1 - \sum_{j \in [c]} \Pbb(j|\xv)^2$，于是

$$
\begin{align*}
    \quad R = \int \Pbb(e|\xv) \Pbb(\xv) \diff \xv = \int \left( 1 - \sum_{j \in [c]} \Pbb(j|\xv)^2 \right) \Pbb(\xv) \diff \xv
\end{align*}
$$

<div class="top-2"></div>

欲证$R$的上界，需考虑$\sum_{j \in [c]} \Pbb(j|\xv)^2$的下界

<!-- slide vertical=true data-notes="" -->

##### <span style="font-weight:900">1-</span>近邻算法 理论分析

---

<div class="top1"></div>

$$
\begin{align*}
    \quad R = \int \Pbb(e|\xv) \Pbb(\xv) \diff \xv = \int \left( 1 - \sum_{j \in [c]} \Pbb(j|\xv)^2 \right) \Pbb(\xv) \diff \xv
\end{align*}
$$

<div class="top-2"></div>

下面考虑$\sum_{j \in [c]} \Pbb(j|\xv)^2$的下界，由柯西不等式有

$$
\begin{align*}
    \quad \sum_{j \neq h^\star(\xv)} & \Pbb(j|\xv)^2 \geq \frac{1}{c-1} \left( \sum_{j \neq l} \Pbb(j|\xv) \right)^2 = \frac{(1 - \Pbb(h^\star(\xv)|\xv))^2}{c-1} = \frac{\Pbb(e^\star|\xv)^2}{c-1} \\[5pt]
    \Longrightarrow 1 & - \sum_{j \in [c]} \Pbb(j|\xv)^2 = 1 - \Pbb(h^\star(\xv)|\xv)^2 - \sum_{j \neq h^\star(\xv)} \Pbb(j|\xv)^2 \\
    & \le 1 - (1 - \Pbb(e^\star|\xv))^2 - \frac{\Pbb(e^\star|\xv)^2}{c-1} \\
    & = 2 \Pbb(e^\star|\xv) - \Pbb(e^\star|\xv)^2 - \frac{\Pbb(e^\star|\xv)^2}{c-1} = 2 \Pbb(e^\star|\xv) - \frac{c}{c-1} \Pbb(e^\star|\xv)^2
\end{align*}
$$

<!-- slide vertical=true data-notes="" -->

##### <span style="font-weight:900">1-</span>近邻算法 理论分析

---

将$\sum_{j \in [c]} \Pbb(j|\xv)^2$的下界回代有

$$
\begin{align*}
    \quad R & = \int \Pbb(e|\xv) \Pbb(\xv) \diff \xv = \int \left( 1 - \sum_{j \in [c]} \Pbb(j|\xv)^2 \right) \Pbb(\xv) \diff \xv \\
    & \le \int \left( 2 \Pbb(e^\star|\xv) - \frac{c}{c-1} \Pbb(e^\star|\xv)^2 \right) \Pbb(\xv) \diff \xv \\
    & = 2 R^\star - \frac{c}{c-1} \int \Pbb(e^\star|\xv)^2 \Pbb(\xv) \diff \xv \quad \longleftarrow \text{第二项是二阶矩} \\
    & = 2 R^\star - \frac{c}{c-1} ({R^\star}^2 + \text{方差}) \\
    & \le R^\star \left( 2 - \frac{c}{c-1} R^\star \right) 
\end{align*}
$$

<!-- slide data-notes="" -->

##### <span style="font-weight:900">k-</span>近邻算法

---

输入：$D = \{ (\xv_i, y_i) \}_{i \in [m]} \in (\Xcal \times \Ycal)^m$，待预测样本$\xv$

<div class="top-3"></div>

输出：$\xv$的类别$y$

1. 根据选定的距离度量，记$D$中与$\xv$最近的$k$个样本构成的集合为$N_k(\xv)$
2. 在$N_k(\xv)$中根据{==多数表决==}确定$\xv$的类别$y$

<div class="top2"></div>

$$
\begin{align*}
    \qquad y = \mathop{\arg \max}_{\yhat \in [c]} \sum_{\xv_i \in N_k(\xv)} \Ibb(y_i = \yhat)
\end{align*}
$$

一些说明：

- $k$选择奇数，避免出现打平的情况，中央政治局常委也都是奇数位
- 当$m \rightarrow \infty$时有$R^\star \le \cdots \le R^{(5)} \le R^{(3)} \le R^{(1)} \le 2 R^\star (1 - R^\star)$
- 在$m$有限的情况下，$k$并不是越大越好，取$k = m$往往欠拟合
- 一些改进的变种：加权多数表决，带拒绝的多数表决

<!-- slide data-notes="" -->

##### 维度灾难

---

