---
presentation:
  margin: 0
  center: false
  transition: "convex"
  enableSpeakerNotes: true
  slideNumber: "c/t"
  navigationMode: "linear"
---

@import "../css/font-awesome-4.7.0/css/font-awesome.css"
@import "../css/theme/solarized.css"
@import "../css/logo.css"
@import "../css/font.css"
@import "../css/color.css"
@import "../css/margin.css"
@import "../css/table.css"
@import "../css/main.css"
@import "../plugin/zoom/zoom.js"
@import "../plugin/customcontrols/plugin.js"
@import "../plugin/customcontrols/style.css"
@import "../plugin/chalkboard/plugin.js"
@import "../plugin/chalkboard/style.css"
@import "../plugin/menu/menu.js"
@import "../js/anychart/anychart-core.min.js"
@import "../js/anychart/anychart-venn.min.js"
@import "../js/anychart/pastel.min.js"
@import "../js/anychart/venn-ml.js"
@import "https://cdn.bootcdn.net/ajax/libs/jquery/3.5.0/jquery.js"

<!-- slide data-notes="" -->

<div class="bottom20"></div>

# 机器学习

<hr class="width50 center">

## 支持向量机

<div class="bottom8"></div>

### 计算机学院 &nbsp;&nbsp; 张腾

#### _tengzhang@hust.edu.cn_

<!-- slide vertical=true data-notes="" -->

##### 大纲

---

@import "../vega/outline.json" {as="vega" .top-2}

<!-- slide vertical=true data-notes="" -->

##### 发明人

---

Vladimir Vapnik：苏联统计学家

<div class="top-3"></div>

Corinna Cortes：纽约 Google Research 的负责人

<div>
    <img src="../img/svm/Vladimir Vapnik.jpg" title="Vladimir Vapnik" width=380px>
    <img src="../img/svm/Corinna Cortes.jpg" title="Corinna Cortes" width=380px class="left4">
</div>

<!-- slide data-notes="" -->

##### 楚河汉界 间隔

---

<div id="board2" class="center" style="width:420px"></div>

<div class="top-33per left-70per bottom-10">
<button id="startBtn" class="top-40per">开始</button>
<button id="clearBtn">清空</button>
</div>

@import "../js/xiangqiboardjs-0.3.3/css/xiangqiboard-0.3.3.css"
@import "../js/xiangqiboardjs-0.3.3/js/xiangqiboard-0.3.3.js"
@import "../js/xiangqiboardjs-0.3.3/js/svm-chess.js"

<!-- slide vertical=true data-notes="" -->

##### 最大间隔准则

---

$D = \{ (\xv_i, y_i) \}_{i \in [m]}$，$\xv_i \in \Xcal \subseteq \Rbb^d$，$y_i \in \{ 1, -1 \}$

超平面$\wv^\top \xv + b = 0$，点$(\xv_i, y_i)$到超平面的距离为$\frac{y_i (\wv^\top \xv_i + b)}{\|\wv\|_2}$

最大间隔准则：最大化最小距离

<div class="top2"></div>

$$
\begin{align*}
    \quad \max_{\wv,b} & ~ \gamma \\ \st & ~ \frac{y_i (\wv^\top \xv_i + b)}{\|\wv\|_2} \ge \gamma, ~ \forall i \in [m]
\end{align*}
$$

@import "../tikz/margin-hyperplane.svg" {.lefta .right6 .width40 .top-20per}

<!-- slide vertical=true data-notes="" -->

##### 最大间隔准则

---

$D = \{ (\xv_i, y_i) \}_{i \in [m]}$，$\xv_i \in \Xcal \subseteq \Rbb^d$，$y_i \in \{ 1, -1 \}$，最大化间隔：

$$
\begin{align*}
    \quad & \max_{\wv,b} ~ \gamma, \quad \st ~ \frac{y_i (\wv^\top \xv_i + b)}{\|\wv\|_2} \ge \gamma, ~ \forall i \in [m] \\
    & \qquad \qquad \qquad \Updownarrow \\
    & \max_{\wv,b} ~ \frac{\hat{\gamma}}{\|\wv\|_2}, \quad \st ~ y_i (\wv^\top \xv_i + b) \ge \hat{\gamma}, ~ \forall i \in [m] \quad \longleftarrow \hat{\gamma} = \gamma \|\wv\|_2 \\
    & \qquad \qquad \qquad \Updownarrow \\
    & \max_{\wv,b} ~ \frac{1}{\|\wv\|_2}, \quad \st ~ y_i (\wv^\top \xv_i + b) \ge 1, ~ \forall i \in [m] \quad \longleftarrow \hat{\gamma} = 1 \\
    & \qquad \qquad \qquad \Updownarrow \\
    & \min_{\wv,b} ~ \frac{1}{2} \|\wv\|_2^2, \quad \st ~ y_i (\wv^\top \xv_i + b) \ge 1, ~ \forall i \in [m]
\end{align*}
$$

<div class="top-2"></div>

$\hat{\gamma}$的取值不影响优化，若$(\wv, b, \hat{\gamma})$是最优解，则$(c \wv, c b, c \hat{\gamma})$也是

<!-- slide vertical=true data-notes="" -->

##### 支持向量机

---

根据最大间隔准则导出支持向量机：

$$
\begin{align*}
    \quad \min_{\wv,b} ~ \frac{1}{2} \|\wv\|_2^2, \quad \st ~ y_i (\wv^\top \xv_i + b) \ge 1, ~ \forall i \in [m]
\end{align*}
$$

该优化问题属于二次规划 (quadratic programming, QP)

- 目标函数是关于$\wv$的强凸 (strongly convex) 二次函数，最优解唯一
- 约束是$m$个线性不等式

<div class="top4"></div>

求解？

- 可调用标准的 QP 求解器进行求解，但有更高效的方法
- 变量个数等于维度$d$，高维空间中求解可能会很低效

<!-- slide data-notes="" -->

##### 对偶问题

---

支持向量机原问题：

$$
\begin{align*}
    \quad \min_{\wv,b} ~ f(\wv) = \frac{1}{2} \|\wv\|_2^2, \quad \st ~ y_i (\wv^\top \xv_i + b) \ge 1, ~ \forall i \in [m]
\end{align*}
$$

引入拉格朗日乘子$\alphav \ge \zerov$，拉格朗日函数为

$$
\begin{align*}
    \quad L(\wv, b, \alphav) = \frac{1}{2} \|\wv\|_2^2 - \sum_{i \in [m]} \alpha_i (y_i (\wv^\top \xv_i + b) - 1)
\end{align*}
$$

<div class="top-2"></div>

定义对偶函数$g(\alphav) = \min_{\wv,b} L(\wv, b, \alphav)$，于是

$$
\begin{align*}
    \quad g(\alphav) = \min_{\wv,b} L(\wv, b, \alphav) \le L(\wv, b, \alphav) \le f(\wv)
\end{align*}
$$

<div class="top-2"></div>

- 上式对任意{==可行==}的$(\wv,b)$均成立
- 设原问题最优解为$(\wv^\star, b^\star)$，则$g(\alphav) \le f(\wv^\star) \triangleq p^\star$

<!-- slide vertical=true data-notes="" -->

##### 对偶问题

---

对$\forall \alphav \ge \zerov$，对偶函数$g(\alphav)$给出了原问题最优值$p^\star$的一个下界

所有下界中最好的下界有多好？即最紧的下界

$$
\begin{align*}
    \quad \max_{\alphav \ge \zerov} g(\alphav) & = \max_{\alphav \ge \zerov} \min_{\wv,b} L(\wv, b, \alphav) \\
    & = \max_{\alphav \ge \zerov} \min_{\wv,b} \left\{ \frac{1}{2} \|\wv\|_2^2 - \sum_{i \in [m]} \alpha_i (y_i (\wv^\top \xv_i + b) - 1) \right\}
\end{align*}
$$

先化简内部优化问题，令$L(\wv, b, \alphav)$关于$\wv$和$b$的偏导为零

$$
\begin{align*}
    \quad \wv = \sum_{i \in [m]} \alpha_i y_i \xv_i, \quad \sum_{i \in [m]} \alpha_i y_i = 0
\end{align*}
$$

<!-- slide vertical=true data-notes="" -->

##### 对偶问题

---

$\wv = \sum_{i \in [m]} \alpha_i y_i \xv_i$，$\sum_{i \in [m]} \alpha_i y_i = 0$，回代可得

$$
\begin{align*}
    \quad \max_{\alphav \ge \zerov} g(\alphav) & = \max_{\alphav \ge \zerov} \min_{\wv,b} \left\{ \frac{1}{2} \|\wv\|_2^2 - \sum_{i \in [m]} \alpha_i (y_i (\wv^\top \xv_i + b) - 1) \right\} \\
    & = \max_{\alphav \ge \zerov} \left\{ - \frac{1}{2} \sum_{i \in [m]} \sum_{j \in [m]} \alpha_i \alpha_j y_i y_j \xv_i^\top \xv_j + \sum_{i \in [m]} \alpha_i \right\} \\
    & = \max_{\alphav \ge \zerov} \left\{ - \frac{1}{2} \alphav^\top \Hv \alphav + \onev^\top \alphav \right\} \quad \longleftarrow [\Hv]_{ij} = y_i y_j \xv_i^\top \xv_j
\end{align*}
$$

<div class="top-2"></div>

这就是支持向量机的对偶问题，依然是 QP 问题

- 将$\max$改成$\min$，去掉负号，目标函数是关于$\alphav$的凸二次函数
- 约束$\alphav \ge \zerov$是$m$个线性不等式，$\sum_{i \in [m]} \alpha_i y_i = 0$是一个等式约束
- 变量个数等于样本数$m$，与维度无关

<!-- slide data-notes="" -->

##### 强对偶

---

支持向量机的原问题和对偶问题分别为

$$
\begin{align*}
    \quad & \min_{\wv,b} ~ f(\wv) = \frac{1}{2} \|\wv\|_2^2, \quad \st ~ y_i (\wv^\top \xv_i + b) \ge 1, ~ \forall i \in [m] \\
    & \max_{\alphav \ge \zerov} ~ g(\alphav) = - \frac{1}{2} \sum_{i \in [m]} \sum_{j \in [m]} \alpha_i \alpha_j y_i y_j \xv_i^\top \xv_j + \sum_{i \in [m]} \alpha_i, \quad \st ~ \yv^\top \alphav = 0
\end{align*}
$$

<div class="top-2"></div>

设最优解分别为$(\wv^\star, b^\star)$、$\alphav^\star$，记$p^\star = f(\wv^\star)$、$d^\star = g(\alphav^\star)$

- {==弱对偶==}：$d^\star \le p^\star$，必然成立
- {==强对偶==}：$d^\star = p^\star$，并不总是成立，但对于支持向量机是成立的

<div class="top2"></div>

我的批注 有一些判定强对偶成立的充分条件，如 Slater 条件

<!-- slide vertical=true data-notes="" -->

##### 最优性条件

---

根据强对偶性

$$
\begin{align*}
    \quad f(\wv^\star) = g(\alphav^\star) & = \min_{\wv,b} L(\wv, b, \alphav^\star) \\
    & = \min_{\wv,b} \left\{ \frac{1}{2} \|\wv\|_2^2 - \sum_{i \in [m]} \alpha_i^\star (y_i (\wv^\top \xv_i + b) - 1) \right\} \\
    & \le \frac{1}{2} \|\wv^\star\|_2^2 - \sum_{i \in [m]} \alpha_i^\star (y_i ({\wv^\star}^\top \xv_i + b^\star) - 1) \le f(\wv^\star)
\end{align*}
$$

<div class="top-3"></div>

因此所有不等号只能取等号，从而有 KKT 条件

$$
\begin{align*}
    \quad \begin{cases}
    \wv^\star = \sum_{i \in [m]} \alpha_i^\star y_i \xv_i, ~ \sum_{i \in [m]} \alpha_i^\star y_i = 0 \quad \longleftarrow \text{第一个不等号取等号} \\
    \alpha_i^\star (y_i ({\wv^\star}^\top \xv_i + b^\star) - 1) = 0, ~ \forall i \in [m] \quad \longleftarrow \text{第二个不等号取等号} \\
    y_i ({\wv^\star}^\top \xv_i + b^\star) \ge 1, ~ \alpha_i^\star \ge 0, ~ \forall i \in [m]
    \end{cases}
\end{align*}
$$

<!-- slide vertical=true data-notes="" -->

##### 最优性条件

---

<div class="top1"></div>

$$
\begin{align*}
    \quad & \min_{\wv,b} ~ \frac{1}{2} \|\wv\|_2^2, \quad \st ~ y_i (\wv^\top \xv_i + b) \ge 1, ~ \forall i \in [m] \\
    & \max_{\alphav \ge \zerov} ~ \left\{ - \frac{1}{2} \sum_{i \in [m]} \sum_{j \in [m]} \alpha_i \alpha_j y_i y_j \xv_i^\top \xv_j + \sum_{i \in [m]} \alpha_i \right\}, \quad \st ~ \yv^\top \alphav = 0 \\[5pt]
    \quad & \text{KKT条件：} \begin{cases}
    \wv^\star = \sum_{i \in [m]} \alpha_i^\star y_i \xv_i, ~ \sum_{i \in [m]} \alpha_i^\star y_i = 0 \\
    \alpha_i^\star (y_i ({\wv^\star}^\top \xv_i + b^\star) - 1) = 0, ~ \forall i \in [m] \quad \text{互补松弛条件} \\
    y_i ({\wv^\star}^\top \xv_i + b^\star) \ge 1, ~ \alpha_i^\star \ge 0, ~ \forall i \in [m]
    \end{cases}
\end{align*}
$$

- $\wv^\star = \sum_{i \in [m]} \alpha_i^\star y_i \xv_i$：原问题最优解只由训练样本线性表出
- 若某个$\alpha_i^\star > 0$，则$y_i ({\wv^\star}^\top \xv_i + b^\star) - 1 = 0$，由此可解出$b^\star$
- 非零$\alpha_i^\star$对应的样本称为{==支持向量==} (<u>s</u>upport <u>v</u>ector, SV)
- $\wv^\star$只与部分支持向量有关，故名{==支持向量机==} (<u>SV</u> <u>m</u>achine, SVM)
- 预测：${\wv^\star}^\top \zv + b^\star = \sum_{i \in [m]} (\alpha_i^\star \xv_i^\top \zv) y_i  + b^\star$，加权多数投票的形式

<!-- slide data-notes="" -->

##### 核支持向量机

---

支持向量机：

$$
\begin{align*}
    \quad & \min_{\wv,b} ~ \frac{1}{2} \|\wv\|_2^2, \quad \st ~ y_i (\wv^\top \xv_i + b) \ge 1, ~ \forall i \in [m] \\
    & \max_{\alphav \ge \zerov} ~ \left\{ - \frac{1}{2} \sum_{i \in [m]} \sum_{j \in [m]} \alpha_i \alpha_j y_i y_j \xv_i^\top \xv_j + \sum_{i \in [m]} \alpha_i \right\}, \quad \st ~ \yv^\top \alphav = 0
\end{align*}
$$

若数据非线性可分怎么办？核支持向量机

$$
\begin{align*}
    \quad & \min_{\wv,b} ~ \frac{1}{2} \|\wv\|_2^2, \quad \st ~ y_i (\wv^\top \class{blue}{\phi(\xv_i)} + b) \ge 1, ~ \forall i \in [m] \\
    & \max_{\alphav \ge \zerov} ~ \left\{ - \frac{1}{2} \sum_{i \in [m]} \sum_{j \in [m]} \alpha_i \alpha_j y_i y_j \class{blue}{\phi(\xv_i)^\top \phi(\xv_j)} + \sum_{i \in [m]} \alpha_i \right\}, \quad \st ~ \yv^\top \alphav = 0
\end{align*}
$$

<!-- slide vertical=true data-notes="" -->

##### 核支持向量机

---

支持向量机：

$$
\begin{align*}
    \quad & \min_{\wv,b} ~ \frac{1}{2} \|\wv\|_2^2, \quad \st ~ y_i (\wv^\top \phi(\xv_i) + b) \ge 1, ~ \forall i \in [m] \\
    & \max_{\alphav \ge \zerov} ~ \left\{ - \frac{1}{2} \sum_{i \in [m]} \sum_{j \in [m]} \alpha_i \alpha_j y_i y_j \class{blue}{\kappa(\xv_i,\xv_j)} + \sum_{i \in [m]} \alpha_i \right\}, \quad \st ~ \yv^\top \alphav = 0 \\
    & \text{预测：} \wv^\top \phi(\zv) + b = \sum_{i \in [m]} \alpha_i y_i \phi(\xv_i)^\top \phi(\zv) + b = \sum_{i \in [m]} \alpha_i y_i \kappa(\xv_i, \zv) + b
\end{align*}
$$

问题：

- 很难确定什么样的核映射能保证样本在新的特征空间线性可分
- 即便恰好找到了这样的核映射，如何确定其没有引起过拟合？

<div class="top2"></div>

方案：允许约束$y_i (\wv^\top \phi(\xv_i) + b) \ge 1$对少数样本不成立

<!-- slide data-notes="" -->

##### 软间隔支持向量机

---

支持向量机：

$$
\begin{align*}
    \quad & \min_{\wv,b} ~ \frac{1}{2} \|\wv\|_2^2, \quad \st ~ y_i (\wv^\top \phi(\xv_i) + b) \ge 1, ~ \forall i \in [m] \\
    & \max_{\alphav \ge \zerov} ~ \left\{ - \frac{1}{2} \sum_{i \in [m]} \sum_{j \in [m]} \alpha_i \alpha_j y_i y_j \class{blue}{\kappa(\xv_i,\xv_j)} + \sum_{i \in [m]} \alpha_i \right\}, \quad \st ~ \yv^\top \alphav = 0
\end{align*}
$$

<div class="top-2"></div>

现允许约束$y_i (\wv^\top \phi(\xv_i) + b) \ge 1$对少数样本不成立

$$
\begin{align*}
    \quad \min_{\wv,b} ~ \frac{1}{2} \|\wv\|_2^2 + C\underbrace{\sum_{i \in [m]} \Ibb(y_i (\wv^\top \phi(\xv_i) + b) < 1) }_{\text{破坏约束的样本个数}}
\end{align*}
$$

<div class="top-2"></div>

难点：指示函数$\Ibb(\cdot)$<span class="blue">非凸非连续</span>，导致问题很难求解

<!-- slide vertical=true data-notes="" -->

##### 软间隔支持向量机

---

用 hinge 损失代替指示函数可得{==软间隔支持向量机==}：

<div class="top1"></div>

$$
\begin{align*}
    \quad \min_{\wv,b} ~ \frac{1}{2} \|\wv\|_2^2 + C\sum_{i \in [m]} \max \{ 0, 1- y_i (\wv^\top \phi(\xv_i) + b) \}
\end{align*}
$$

<div class="top-2"></div>

令$\epsilon_i = \max \{ 0, 1- y_i (\wv^\top \phi(\xv_i) + b) \}$可得其等价约束形式：

<div class="top1"></div>

$$
\begin{align*}
    \quad \min_{\wv,b} & ~ \frac{1}{2} \|\wv\|_2^2 + C\sum_{i \in [m]} \epsilon_i \\[2pt]
    \st & ~ y_i (\wv^\top \phi(\xv_i) + b) \ge 1 - \epsilon_i, ~ \epsilon_i \ge 0, ~ \forall i \in [m]
\end{align*}
$$

对比前面的{==硬间隔支持向量机==}可以发现就多了$\epsilon_i$

$\epsilon_i$也叫{==松弛变量==} (slack variable)，刻画了约束被破坏的程度

<!-- slide vertical=true data-notes="" -->

##### 软间隔支持向量机

---

软间隔支持向量机原问题

$$
\begin{align*}
    \quad \text{无约束形式：} \min_{\wv,b} & ~ \frac{1}{2} \|\wv\|_2^2 + C\sum_{i \in [m]} \max \{ 0, 1- y_i (\wv^\top \phi(\xv_i) + b) \} \\
    \quad \text{有约束形式：} \min_{\wv,b} & ~ \frac{1}{2} \|\wv\|_2^2 + C\sum_{i \in [m]} \epsilon_i \\
    \st & ~ y_i (\wv^\top \phi(\xv_i) + b) \ge 1 - \epsilon_i, ~ \epsilon_i \ge 0, ~ \forall i \in [m]
\end{align*}
$$

软间隔支持向量机对偶问题

$$
\begin{align*}
    \quad \max_{0 \le \alpha_i \class{blue}{\le C}} ~ \left\{ - \frac{1}{2} \sum_{i \in [m]} \sum_{j \in [m]} \alpha_i \alpha_j y_i y_j \kappa(\xv_i,\xv_j) + \sum_{i \in [m]} \alpha_i \right\}, \quad \st ~ \yv^\top \alphav = 0
\end{align*}
$$

<div class="top-2"></div>

我的批注 区别就是$\alpha_i$多了个上界约束

<!-- slide data-notes="" -->

##### 支持向量机的求解

---

<div class="top1"></div>

$$
\begin{align*}
    \quad & \min_{\wv,b} ~ \frac{1}{2} \|\wv\|_2^2 + C\sum_{i \in [m]} \max \{ 0, 1- y_i (\wv^\top \phi(\xv_i) + b) \} \\
    \quad & \max_{0 \le \alpha_i \le C} ~  \left\{ - \frac{1}{2} \sum_{i \in [m]} \sum_{j \in [m]} \alpha_i \alpha_j y_i y_j \kappa(\xv_i,\xv_j) + \sum_{i \in [m]} \alpha_i \right\}, \quad \st ~ \yv^\top \alphav = 0
\end{align*}
$$

当采用线性核函数时，原问题、对偶问题择其易解者解之

- 原问题无约束，可直接用随机梯度下降及其变种，参考 Pegasos
- 对偶问题可采用 SMO，每次取一对$(\alpha_i, \alpha_j)$进行优化，参考 libSVM

<div class="top2"></div>

当采用非线性核函数时，一般只考虑对偶问题

省略$b$可去掉等式约束$\yv^\top \alphav = 0$，所有$\alpha_i$去耦合，参考 liblinear

<!-- slide data-notes="" -->

##### 正则化项 + 损失函数

---

<div class="top2"></div>

$$
\begin{align*}
    \quad \min_{\wv,b} ~ \frac{1}{2} \underbrace{\|\wv\|_2^2}_{\text{正则化项}} + C\sum_{i \in [m]} \underbrace{\max \{ 0, 1- y_i (\wv^\top \phi(\xv_i) + b) \}}_{\text{损失函数}}
\end{align*}
$$

- $\ell_2$正则$\| \wv \|_2^2$，得到稠密的$\wv$
- $\ell_1$正则$\| \wv \|_1$，得到稀疏的$\wv$，附带特征选择的作用
- $\ell_\infty$正则$\| \wv \|_\infty$，得到所有分量值相同的$\wv$
- $\ell_{2,1}$正则$\sum_j \| \wv_j \|_2$，特征分组，组内稠密，组间稀疏
- $\ell_{1,2}$正则$(\sum_j \| \wv_j \|_1)^2$，特征分组，组内稀疏，组间稠密
- 弹性网：$\ell_1$正则和$\ell_2$正则的线性组合
- OSCAR：$\ell_1$正则和成对$\ell_\infty$正则的线性组合

<!-- slide vertical=true data-notes="" -->

##### 正则化项 + 损失函数

---

<div class="top2"></div>

$$
\begin{align*}
    \quad \min_{\wv,b} ~ \frac{1}{2} \underbrace{\|\wv\|_2^2}_{\text{正则化项}} + C\sum_{i \in [m]} \underbrace{\max \{ 0, 1- y_i (\wv^\top \phi(\xv_i) + b) \}}_{\text{损失函数}}
\end{align*}
$$

- hinge 损失：$l(y, f(\xv)) = \max \{ 0, 1 - y f(\xv) \}$，软间隔支持向量机
- 平方 hinge 损失：$l(y, f(\xv)) = [\max \{ 0, 1 - y f(\xv) \}]^2$
- 平方损失：$l(y, f(\xv)) = (y - f(\xv))^2$，岭回归
- $\epsilon$-不敏感损失：$l(y, f(\xv)) = \max \{ 0, |y - f(\xv)| - \epsilon \}$，支持向量回归
- 指数损失：$l(y, f(\xv)) = \exp (- y f(\xv))$
- 对率损失：$l(y, f(\xv)) = \log (1 + \exp (- y f(\xv)))$，对率回归

<!-- slide vertical=true data-notes="" -->

##### 损失函数

---

@import "../python/surrogate-loss.svg" {title="各种替代损失函数" .center .top4 .width70}
