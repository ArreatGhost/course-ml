---
presentation:
  margin: 0
  center: false
  transition: "convex"
  enableSpeakerNotes: true
  slideNumber: "c/t"
  navigationMode: "linear"
---

@import "../css/font-awesome-4.7.0/css/font-awesome.css"
@import "../css/theme/solarized.css"
@import "../css/logo.css"
@import "../css/font.css"
@import "../css/color.css"
@import "../css/margin.css"
@import "../css/table.css"
@import "../css/main.css"
@import "../plugin/zoom/zoom.js"
@import "../plugin/customcontrols/plugin.js"
@import "../plugin/customcontrols/style.css"
@import "../plugin/chalkboard/plugin.js"
@import "../plugin/chalkboard/style.css"
@import "../plugin/menu/menu.js"
@import "../js/anychart/anychart-core.min.js"
@import "../js/anychart/anychart-venn.min.js"
@import "../js/anychart/pastel.min.js"
@import "../js/anychart/venn-ml.js"
@import "https://cdn.bootcdn.net/ajax/libs/jquery/3.5.0/jquery.js"

<!-- slide data-notes="" -->

<div class="bottom20"></div>

# 机器学习

<hr class="width50 center">

## k-近邻法

<div class="bottom8"></div>

### 计算机学院 &nbsp;&nbsp; 张腾

#### _tengzhang@hust.edu.cn_

<!-- slide vertical=true data-notes="" -->

##### 大纲

---

@import "../vega/outline.json" {as="vega" .top-2}

<!-- slide data-notes="" -->

##### <span style="font-weight:900">k-</span>近邻法

---

基本假设：{==相似的样本属于相同的类别==}

<div class="top-2"></div>

如何刻画相似？距离函数：$\dist(\cdot, \cdot): \Xcal \times \Xcal \mapsto \Rbb^+$

<div class="top-2"></div>

集合、距离函数对$(\Xcal, \dist(\cdot, \cdot))$构成{==度量空间==} (metric space)

<div class="top2"></div>

输入：$D = \{ (\xv_i, y_i) \}_{i \in [m]} \in (\Xcal \times \Ycal)^m$，近邻数$k$，待预测样本$\xv$

<div class="top-3"></div>

输出：$\xv$的类别$y$

1. 求解$N_k(\xv) \subseteq D$使得$|N_k(\xv)| = k$且对$\forall (\xv', y') \in D \setminus N_k(\xv)$有$\dist(\xv, \xv') \geq \max_{\zv \in N_k(\xv)} \dist (\xv, \zv)$
2. 输出$\mode(\{ y'': (\xv'', y'') \in N_k(\xv) \})$，其中$\mode(\cdot)$表示众数

<div class="top4"></div>

我的批注 近邻法没有{==显式==}的学习过程

<!-- slide vertical=true data-notes="" -->

##### 空间划分 <span style="font-weight:900">1-</span>近邻

---

@import "../tikz/knn.svg" {.center .width50 .top5}

<!-- slide vertical data-notes="" -->

##### 超参设置

---

近邻数$k$：取值范围$[m] \wedge \{2 \Zbb + 1\}$

- 奇数可保证取众数时不会出现打平的情况，zyzzj 常委都是奇数位
- 越小越容易过拟合，越大越容易欠拟合，实操时可通过交叉验证选取

<div class="top2"></div>

距离函数：

- 闵可夫斯基距离：$\dist(\xv, \zv) = \| \xv - \zv \|_p$
- 马氏距离：$\dist_\Mv (\xv, \zv) \triangleq \sqrt{(\xv - \zv)^\top \Mv (\xv - \zv)}$，比如$\Mv$为对角阵$\diag\{w_1, \ldots, w_d\}$时，马氏距离就是加权平方距离$\sqrt{\sum_{j \in [d]} w_j (x_j - z_j)^2}$

<div class="top2"></div>

度量学习 (metric learning)：找一个更好的特征空间，记$\Mcal$为同类样本对集合，$\Ccal$为异类样本对集合

$$
\begin{align*}
    \quad \min_\Mv & \sum_{(\xv_i, \xv_j) \in \Mcal} \dist(\xv_i, \xv_j), \quad \st \sum_{(\xv_i, \xv_j) \in \Ccal} \dist(\xv_i, \xv_j) \ge 1, ~ \Mv \succeq \zerov
\end{align*}
$$

<!-- slide vertical data-notes="" -->

##### 优劣

---

优点

- 简单 (概念上、实现上)
- 无训练过程，只需存下数据，惰性学习 (lazy learning)
- 样本极少时也能用
- $\Xcal$维度不高时效果很好
- {==一致性==}：若贝叶斯最优分类器的错误率$R^\star = 0$，k-近邻也能渐进达到

<div class="top4"></div>

缺点

- 预测很慢，要计算待预测样本与训练集中所有样本的距离
- {==维度灾难==}：高维空间中的距离会失效，k-近邻效果很差

<!-- slide data-notes="" -->

##### 理论分析 <span style="font-weight:900">1-</span>近邻法

---

定理：设$(\Xcal, \dist(\cdot, \cdot))$是{==可分==}度量空间，标记集合$\Ycal = \{ 1, -1 \}$，贝叶斯最优分类器$h^\star(\xv) = \mathop{\arg\max}_{y \in \Ycal} \Pbb(y|\xv)$的错误率为$R^\star$，训练集$D = \{ (\xv_i, y_i) \}_{i \in [m]} \in (\Xcal \times \Ycal)^m$，1-近邻法的错误率为$R_m$，记$R = \lim_{m \rightarrow \infty} R_m$，则$R^\star \le R \le 2 R^\star (1 - R^\star)${==以概率 1 成立==}

一些说明：

- 下界是显然的，不可能比贝叶斯最优分类器更好
- 1-近邻法最坏情况下错误率不超过贝叶斯最优分类器的 2 倍
- 当$R^\star = 0$ (两类完全分开) 或$R^\star = 1/2$ (两类完全重叠) 时，界是紧的
- 以概率 1 成立又称{==几乎必然==} (almost surely, a.s.) 成立

<!-- slide data-notes="" -->

##### 概念解释 空间

---

空间 = 集合 + 结构

- 集合：把需要研究元素放到一起
- 结构：描述元素必须遵循的规则

<div class="top2"></div>

代数结构：加法和数乘的 8 条公理，线性空间，也叫向量空间

<div class="top-2"></div>

线性空间无法计算两个元素的距离，从而无法谈序列的收敛性

引入几何结构刻画元素间的亲疏远近，由弱到强依次有

- 邻域 (开集族)：拓扑空间
- 距离$\dist(\cdot, \cdot): \Xcal \times \Xcal \mapsto \Rbb^+$：度量空间
- 代数结构 + $\|\cdot\|$：赋范空间，$\dist(\xv, \zv) = \| \xv - \zv \|$
- 代数结构 + $\langle \cdot, \cdot \rangle$：内积空间，$\| \xv - \zv \|_2^2 = \langle \xv, \xv \rangle - 2 \langle \xv, \zv \rangle + \langle \zv, \zv \rangle$

<!-- slide vertical=true data-notes="" -->

##### 概念解释 空间

---

完备性：对极限运算封闭，空间内的柯西序列能收敛

- $\Qbb$不完备，$\lim_{n \rightarrow \infty} (1 + 1 / n)^n = e$，$\Qbb$的完备化是$\Rbb$

<div class="top2"></div>

@import "../dot/space.dot" {.center}

<div class="top-3"></div>

可分性：具有可数稠密子集

- 若度量空间$\Xcal$的子集$\Mcal$满足对$\forall x \in \Xcal$，$x$的任意邻域与$\Mcal$交集非空，则称$\Mcal$在$\Xcal$中稠密
- $\Qbb$在$\Rbb$中稠密，$\Qbb$可数，因此$\Rbb$可分

<!-- slide data-notes="" -->

##### 概念解释 几乎必然

---

引理：若$(\Xcal, \dist(\cdot, \cdot))$是{==可分==}度量空间，设

$$
\begin{align*}
    \quad D_1 = \{ \xv_1 \}, ~ D_2 = \{ \xv_1, \xv_2 \}, ~ \ldots, D_n = \{ \xv_1, \xv_2, \ldots, \xv_n \}, ~ \ldots, ~ \xv_i \overset{\text{iid}}{\sim} \Dcal
\end{align*}
$$

<div class="top-3"></div>

对任意$\xv$，记$\xvhat_n = \mathop{\arg \min}_{\zv \in D_n} \dist (\xv, \zv)$，则序列$\xvhat_n \overset{\text{a.s.}}{\rightarrow} \xv$

证明：记以$\xv$为球心、$r$为半径的球为$B_\xv(r)$

若对$\forall r > 0$有$\Pbb(B_\xv(r)) > 0$，则

$$
\begin{align*}
    \quad \Pbb(\dist(\xvhat_n, \xv) > r) = (1 - \Pbb(B_\xv(r)))^n \rightarrow 0
\end{align*}
$$

<div class="top-4"></div>

由$r$的任意性知$\Pbb(\dist(\xvhat_n, \xv) = 0) \rightarrow 1$，从而$\xvhat_n \overset{\text{a.s.}}{\rightarrow} \xv$

最后还需说明“对$\forall r > 0$有$\Pbb(B_\xv(r)) > 0$”以概率 1 成立

<!-- slide vertical=true data-notes="" -->

##### 概念解释 几乎必然

---

引理：若$(\Xcal, \dist(\cdot, \cdot))$是{==可分==}度量空间，设

$$
\begin{align*}
    \quad D_1 = \{ \xv_1 \}, ~ D_2 = \{ \xv_1, \xv_2 \}, ~ \ldots, D_n = \{ \xv_1, \xv_2, \ldots, \xv_n \}, ~ \ldots, ~ \xv_i \overset{\text{iid}}{\sim} \Dcal
\end{align*}
$$

<div class="top-3"></div>

对任意$\xv$，记$\xvhat_n = \mathop{\arg \min}_{\zv \in D_n} \dist (\xv, \zv)$，则序列$\xvhat_n \overset{\text{a.s.}}{\rightarrow} \xv$

证明 (续)：“对$\forall r > 0$有$\Pbb(B_\xv(r)) > 0$”的否命题为“存在$r > 0$使得$\Pbb(B_\xv(r)) = 0$”，设这样的$\xv$构成集合$N$，只需证$\Pbb(N) = 0$

设$\Xcal$的可数稠密子集为$\Acal$，由可分性，存在$\av \in B_\xv(r/3) \wedge \Acal$，于是$\xv \in B_\av (r/2) \subseteq B_\xv(r)$，从而$\Pbb(B_\av (r/2)) = 0$

若上述过程产生多个以$\av$为球心的球，取并集 (最大半径球)，注意$\Acal$可数，即可数个概率为零的球可覆盖全部$\xv$，$\Pbb(N) = 0$

<!-- slide data-notes="" -->

##### 理论分析 <span style="font-weight:900">1-</span>近邻法

---

定理：设$(\Xcal, \dist(\cdot, \cdot))$是{==可分==}度量空间，标记集合$\Ycal = \{ 1, -1 \}$，贝叶斯最优分类器$h^\star(\xv) = \mathop{\arg\max}_{y \in \Ycal} \Pbb(y|\xv)$的错误率为$R^\star$，训练集$D = \{ (\xv_i, y_i) \}_{i \in [m]} \in (\Xcal \times \Ycal)^m$，1-近邻法的错误率为$R_m$，记$R = \lim_{m \rightarrow \infty} R_m$，则$R^\star \le R \le 2 R^\star (1 - R^\star)${==以概率 1 成立==}

思路：在空间可分的条件下，1-近邻序列$\xvhat_n \overset{\text{a.s.}}{\rightarrow} \xv$，从而1-近邻的错误率 $\overset{\text{a.s.}}{\rightarrow}$ 在$\xv$处采样两次标记不同的概率

<div class="top1"></div>

$$
\begin{align*}
    \quad \Pbb(e|\xv) & = \Pbb(y=1|\xv)\Pbb(y=-1|\xv) + \Pbb(y=-1|\xv)\Pbb(y=1|\xv) \\
    & = 2 \Pbb(y=1|\xv) \Pbb(y=-1|\xv) \\
    & = 2 \underbrace{\Pbb(y=h^\star(\xv)|\xv)}_{h^\star(\xv)\text{的正确率}\qquad} \underbrace{(1 - \Pbb(y=h^\star(\xv)|\xv))}_{h^\star(\xv)\text{的错误率}\qquad}
\end{align*}
$$

<div class="top-3"></div>

接近右边的形式了，再对$\xv$求期望即可

<!-- slide vertical=true data-notes="" -->

##### 理论分析 <span style="font-weight:900">1-</span>近邻法

---

证明：贝叶斯最优分类器$h^\star(\xv) = \mathop{\arg\max}_{y \in \Ycal} \Pbb(y|\xv)$的错误率

$$
\begin{align*}
    \quad R^\star = \int_\Xcal \underbrace{(1 - \Pbb(h^\star(\xv) | \xv))}_{h^\star(\xv)\text{的错误率}\qquad} \Pbb(\xv) \diff \xv = \int_\Xcal \Pbb (e^\star | \xv) \Pbb(\xv) \diff \xv
\end{align*}
$$

<div class="top-2"></div>

对任意$\xv$，1-近邻法预测出错的概率为

$$
\begin{align*}
    \quad \Pbb(e|\xv) & = \Pbb(y=1|\xv) \Pbb(\yhat=-1|\xvhat) + \Pbb(y=-1|\xv) \Pbb(\yhat=1|\xvhat) \\
    & \overset{\text{a.s.}}{\rightarrow} 2 \Pbb(y=1|\xv) \Pbb(y=-1|\xv) \\
    & = 2 \Pbb(h^\star(\xv)|\xv) (1 - \Pbb(h^\star(\xv)|\xv)) \\
    & = 2 \Pbb(e^\star|\xv) (1 - \Pbb(e^\star|\xv))
\end{align*}
$$

<!-- slide vertical=true data-notes="" -->

##### 理论分析 <span style="font-weight:900">1-</span>近邻法

---

<div class="top1"></div>

$$
\begin{align*}
    \quad & R^\star = \int_\Xcal \underbrace{(1 - \Pbb(h^\star(\xv) | \xv))}_{h^\star(\xv)\text{的错误率}\qquad} \Pbb(\xv) \diff \xv = \int_\Xcal \Pbb (e^\star | \xv) \Pbb(\xv) \diff \xv \\
    & \Pbb(e|\xv) \overset{\text{a.s.}}{\rightarrow} 2 \Pbb(e^\star|\xv) (1 - \Pbb(e^\star|\xv))
\end{align*}
$$

<div class="top-2"></div>

根据控制收敛定理

$$
\begin{align*}
    \quad \Pbb(e) & = \int_\Xcal \Pbb(e|\xv) \Pbb(\xv) \diff \xv \\
    & \overset{\text{a.s.}}{\rightarrow} 2 \int_\Xcal (\Pbb(e^\star|\xv) - \Pbb(e^\star|\xv)^2) \Pbb(\xv) \diff \xv \\
    & = 2 R^\star - 2 \int_\Xcal \Pbb(e^\star|\xv)^2 \Pbb(\xv) \diff \xv \quad \longleftarrow \text{第二项是二阶矩} \\
    & = 2 R^\star - 2 ({R^\star}^2 + \text{方差}) \\
    & \le 2 R^\star - 2 {R^\star}^2 \\
    & = 2 R^\star (1 - R^\star)
\end{align*}
$$

<!-- slide data-notes="" -->

##### 理论分析 推广到多类

---

<div class="top1"></div>

$$
\begin{align*}
    \quad R = \int_\Xcal \Pbb(e|\xv) \Pbb(\xv) \diff \xv \overset{\text{a.s.}}{\rightarrow} \int_\Xcal \left( 1 - \sum_{j \in [c]} \Pbb(j|\xv)^2 \right) \Pbb(\xv) \diff \xv
\end{align*}
$$

<div class="top-2"></div>

下面考虑$\sum_{j \in [c]} \Pbb(j|\xv)^2$的下界，由柯西不等式有

$$
\begin{align*}
    \quad \sum_{j \neq h^\star(\xv)} & \Pbb(j|\xv)^2 \geq \frac{( \sum_{j \neq h^\star(\xv)} \Pbb(j|\xv) )^2}{c-1}  = \frac{(1 - \Pbb(h^\star(\xv)|\xv))^2}{c-1} = \frac{\Pbb(e^\star|\xv)^2}{c-1} \\[5pt]
    \Longrightarrow 1 & - \sum_{j \in [c]} \Pbb(j|\xv)^2 = 1 - \Pbb(h^\star(\xv)|\xv)^2 - \sum_{j \neq h^\star(\xv)} \Pbb(j|\xv)^2 \\
    & \le 1 - (1 - \Pbb(e^\star|\xv))^2 - \frac{\Pbb(e^\star|\xv)^2}{c-1} \\
    & = 2 \Pbb(e^\star|\xv) - \Pbb(e^\star|\xv)^2 - \frac{\Pbb(e^\star|\xv)^2}{c-1} = 2 \Pbb(e^\star|\xv) - \frac{c}{c-1} \Pbb(e^\star|\xv)^2
\end{align*}
$$

<!-- slide vertical=true data-notes="" -->

##### 理论分析 推广到多类

---

将$\sum_{j \in [c]} \Pbb(j|\xv)^2$的下界回代有

$$
\begin{align*}
    \quad R & = \int_\Xcal \Pbb(e|\xv) \Pbb(\xv) \diff \xv = \int_\Xcal \left( 1 - \sum_{j \in [c]} \Pbb(j|\xv)^2 \right) \Pbb(\xv) \diff \xv \\
    & \le \int_\Xcal \left( 2 \Pbb(e^\star|\xv) - \frac{c}{c-1} \Pbb(e^\star|\xv)^2 \right) \Pbb(\xv) \diff \xv \\
    & = 2 R^\star - \frac{c}{c-1} \int_\Xcal \Pbb(e^\star|\xv)^2 \Pbb(\xv) \diff \xv \quad \longleftarrow \text{第二项是二阶矩} \\
    & = 2 R^\star - \frac{c}{c-1} ({R^\star}^2 + \text{方差}) \\
    & \le R^\star \left( 2 - \frac{c}{c-1} R^\star \right)
\end{align*}
$$

令$c=2$可导出前面的界

<!-- slide data-notes="" -->

##### <span style="font-weight:900">k-</span>近邻 vs. <span style="font-weight:900">1-</span>近邻

---

当$m \rightarrow \infty$时有$R^\star \le \cdots \le R^{(5)} \le R^{(3)} \le R^{(1)} \le 2 R^\star (1 - R^\star)$

<div class="top-2"></div>

在$m$有限的情况下，$k$并不是越大越好，越大越欠拟合

考虑如下例子：$\Pbb(y=1) = \Pbb(y=-1) = 1/2$，$\Pbb(\xv | y=1)$均匀分布在$[99,101]$，$\Pbb(\xv | y=-1)$均匀分布在$[-101,-99]$

- 1-近邻出错：训练集中只有一类样本而待预测样本为另一类
- 3-近邻出错：训练集中某一类样本数$\le 1$，且待预测样本也为该类
- 5-近邻出错：训练集中某一类样本数$\le 2$，且待预测样本也为该类

<div class="top2"></div>

$$
\begin{align*}
    \quad \Pbb(e_1) & = \frac{1}{2} \frac{1}{2^m} + \frac{1}{2} \frac{1}{2^m} \\
    \Pbb(e_3) & = \Pbb(e_1) + 2 \binom{m}{1} \frac{1}{2} \frac{1}{2^m}, ~ \Pbb(e_5) = \Pbb(e_1) + \Pbb(e_3) + 2 \binom{m}{2} \frac{1}{2} \frac{1}{2^m}
\end{align*}
$$

<!-- slide data-notes="" -->

##### <span style="font-weight:900">k-</span>近邻法 变种

---

{==加权==}多数表决，例如权重取每个近邻到待预测样本距离的倒数

理论上加权没有优势，可以证明：最近邻权重为$1/k + \epsilon$、其它近邻权重为$1/k - \epsilon/(k-1)$时，泛化错误率差于标准的多数表决

<div class="top4"></div>

{==带拒绝的==}多数表决，例如$k$个近邻中至少$l$个近邻都属于同一类时才进行预测，设其错误率为$R^{(k,l)}$，理论上可以证明

$$
\begin{align*}
    \quad R^{(k,k)} \le R^{(k,k-1)} \le \cdots \le R^{(k,\lceil k/2 \rceil+1)} \le R^\star \le R^{(k,\lceil k/2 \rceil)} = R^{(k)}
\end{align*}
$$

我的批注 这里超越贝叶斯最优分类器其实是因为拒绝了难预测的样本

<!-- slide data-notes="" -->

##### 维度灾难

---

设$\Xcal = [0,1]^d$为单位立方体，训练样本均匀分布

对任意待测试样本$\xv$，设所有包含其$k$-近邻的立方体变长为$l$

$l^d \approx k / m$，则$l \approx \sqrt[d]{k/m}$，取$m=1000$、$k=10$

<div class="threelines column1-border1-right-solid-head row1-column1-border1-right-solid head-highlight-1 tr-hover row8-border-top-dashed">

| $d$ |  2  |  10  |  100  |  1000  |
| :-: | :-: | :--: | :---: | :----: |
| $l$ | 0.1 | 0.63 | 0.955 | 0.9954 |

</div>

当维度达到 1000 维时，10-近邻近乎覆盖整个$\Xcal$，已经不是$\xv$的邻域了

<!-- slide vertical=true data-notes="" -->

##### 维度灾难

---

当维度很高时，任意一对样本的距离会集中在很小的范围内

@import "../python/dimension-curse.svg" {.center .width80 .top2}
