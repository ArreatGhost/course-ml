---
presentation:
  margin: 0
  center: false
  transition: "convex"
  enableSpeakerNotes: true
  slideNumber: "c/t"
  navigationMode: "linear"
---

@import "../css/font-awesome-4.7.0/css/font-awesome.css"
@import "../css/theme/solarized.css"
@import "../css/logo.css"
@import "../css/font.css"
@import "../css/color.css"
@import "../css/margin.css"
@import "../css/table.css"
@import "../css/main.css"
@import "../plugin/zoom/zoom.js"
@import "../plugin/customcontrols/plugin.js"
@import "../plugin/customcontrols/style.css"
@import "../plugin/chalkboard/plugin.js"
@import "../plugin/chalkboard/style.css"
@import "../plugin/menu/menu.js"
@import "../js/anychart/anychart-core.min.js"
@import "../js/anychart/anychart-venn.min.js"
@import "../js/anychart/pastel.min.js"
@import "../js/anychart/venn-ml.js"

<!-- slide data-notes="" -->

<div class="bottom20"></div>

# 机器学习

<hr class="width50 center">

## 神经网络

<div class="bottom8"></div>

### 计算机学院 &nbsp;&nbsp; 张腾

#### _tengzhang@hust.edu.cn_

<!-- slide vertical=true data-notes="" -->

##### 大纲

---

@import "../vega/outline.json" {as="vega" .top-2}

<!-- slide data-notes="" -->

##### 感知机

---

若标记集合$\Ycal = \{ 0, 1 \}$，感知机采用阶跃函数作为激活函数

$$
\begin{align*}
    \quad y & = \sgn(\wv^\top \xv + b) \\[4pt]
    & = \begin{cases} 1, & \wv^\top \xv + b \ge 0 \\ 0, & \wv^\top \xv + b < 0 \end{cases}
\end{align*}
$$

常用对数几率函数替代阶跃函数

$$
\begin{align*}
    \quad y & = \logistic(\wv^\top \xv + b) \\
    & = \frac{1}{1 + \exp(-(\wv^\top \xv + b))}
\end{align*}
$$

对数几率函数的输出是连续的$[0,1]$，可将其视为$\Pr(y = 1 | \xv)$

@import "../python/activation.svg" {.width40 .left55per .top-42per}

<!-- slide vertical=true data-notes="" -->

##### 对数几率回归

---

将对数几率函数的输出视为后验概率估计$\Pr(y = 1 | \xv)$

$$
\begin{align*}
    \quad & \Pr(y = 1 | \xv) = \frac{1}{1 + \exp(-(\wv^\top \xv + b))} \\[4pt]
    & \Pr(y = 0 | \xv) = \frac{\exp(-(\wv^\top \xv + b))}{1 + \exp(-(\wv^\top \xv + b))}
\end{align*}
$$

<div class="top-2"></div>

两式相除可得对(数几)率回归 (<u>l</u>ogistic <u>r</u>egression, LR)

$$
\begin{align*}
    \quad \exp(\wv^\top \xv + b) = \frac{\Pr(y = 1 | \xv)}{\Pr(y = 0 | \xv)} \Longrightarrow \wv^\top \xv + b = \ln \frac{\Pr(y = 1 | \xv)}{\Pr(y = 0 | \xv)}
\end{align*}
$$

- 正类概率除以负类概率称为几率 (odds)
- 对率回归，顾名思义就是用线性函数拟合几率的对数 (logit)
- 有人将其译为逻辑(斯蒂)回归，逻辑 (logic) 与 (logistic) 相去甚远

<!-- slide data-notes="" -->

##### 极大似然求解

---

对率回归中的参数$\wv,b$可通过极大似然法求解

$$
\begin{align*}
    \quad \max_{\wv,b} \sum_{i \in [m]} \ln \Pr(y_i | \xv_i; \wv, b)
\end{align*}
$$
