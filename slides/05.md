---
presentation:
  margin: 0
  center: false
  transition: "convex"
  enableSpeakerNotes: true
  slideNumber: "c/t"
  navigationMode: "linear"
---

@import "../css/font-awesome-4.7.0/css/font-awesome.css"
@import "../css/theme/solarized.css"
@import "../css/logo.css"
@import "../css/font.css"
@import "../css/color.css"
@import "../css/margin.css"
@import "../css/table.css"
@import "../css/main.css"
@import "../plugin/zoom/zoom.js"
@import "../plugin/customcontrols/plugin.js"
@import "../plugin/customcontrols/style.css"
@import "../plugin/chalkboard/plugin.js"
@import "../plugin/chalkboard/style.css"
@import "../plugin/menu/menu.js"
@import "../js/anychart/anychart-core.min.js"
@import "../js/anychart/anychart-venn.min.js"
@import "../js/anychart/pastel.min.js"
@import "../js/anychart/venn-ml.js"

<!-- slide data-notes="" -->

<div class="bottom20"></div>

# 机器学习

<hr class="width50 center">

## 感知机

<div class="bottom8"></div>

### 计算机学院 &nbsp;&nbsp; 张腾

#### _tengzhang@hust.edu.cn_

<!-- slide vertical=true data-notes="" -->

##### 大纲

---

@import "../vega/outline.json" {as="vega" .top-2}

<!-- slide data-notes="" -->

##### 剑宗气宗 路线之争

---

符号学派：明确的概念表示

连接学派：“黑箱”模型

- 从知识获取的角度来说，连接学派有先天性的缺点
- 有高效的反向传播 (BP) 算法，实际挺好用
- 超参数巨多且设置缺乏理论指导，全靠手工“调参”
- 显著降低使用者门槛，为机器学习技术走向工程实践带来便利

<!-- slide vertical=true data-notes="" -->

##### 发展历史

---

@import "../mermaid/nn.mermaid" {.center .top-3 .bottom-2}

- 八十年代红极一时：x86 系列 CPU 和内存条技术较七十年代显著提高
- 近十年梅开二度：大数据防止过拟合，显卡等计算设备性能显著提升

<!-- slide data-notes="" -->

##### M-P 神经元模型

---

感知机的基本结构单元为{==神经元==} (neuron)

- 接收来自$d$个其它神经元传来的输入信号$x_1, \ldots, x_d$
- 加权输入总和$\sum_{i \in [d]} w_i x_i$与阈值$b$进行比较
- 通过{==激活函数==} (activation function) $h(\cdot)$输出

@import "../tikz/neuron.svg" {.width45 .left10per .top5per}

<!-- slide vertical=true data-notes="" -->

##### 激活函数

---

<div class="top2"></div>

阶跃函数：

$$
\begin{align*}
    \quad \sgn(x) = \begin{cases} 1, & x \ge 0 \\ 0, & x < 0 \end{cases}
\end{align*}
$$

符号函数

$$
\begin{align*}
    \quad \sign(x) = \begin{cases} 1, & x > 0 \\ 0, & x = 0 \\ -1, & x < 0 \end{cases}
\end{align*}
$$

对数几率函数

$$
\begin{align*}
    \quad \mathrm{logistic}(x) = \frac{1}{1 + \exp(-x)}
\end{align*}
$$

@import "../python/activation.svg" {.width45 .left50per .top-35per}

<!-- slide data-notes="" -->

##### 感知机

---

感知机由输入层、输出层两层神经元组成

$$
\begin{align*}
    y = \sgn (\wv^\top \xv - b) = \sgn \left( \begin{bmatrix} \wv \\ b \end{bmatrix}^\top \begin{bmatrix} \xv \\ -1 \end{bmatrix} \right)
\end{align*}
$$

<div class="top-4"></div>

即为每个样本引入额外一维特征

<div class="top4"></div>

感知机可以实现与、或、非运算

- 与：$\sgn(x_1 + x_2 - 1.5) = \begin{cases} 1, & x_1 = x_2 = 1 \\ 0, & \ow \end{cases}$
- 或：$\sgn(x_1 + x_2 - 0.5) = \begin{cases} 0, & x_1 = x_2 = 0 \\ 1, & \ow \end{cases}$
- 非：$\sgn(- x_1 + 0.5) = \begin{cases} -1, & x_1 = 1 \\ 1, & x_1 = -1 \end{cases}$

@import "../tikz/perceptron.svg" {.width38 .left58per .top-40per}

<!-- slide vertical=true data-notes="" -->

##### 感知机学习算法

---

输入：训练集$D = \{ (\xv_i, y_i) \}_{i \in [m]} \in (\Rbb^d \times \{ \pm 1 \})^m$，学习率$\eta > 0$

1. 初始化$\wv$
2. 在训练集中选取数据$(\xv_i, y_i)$
3. 如果$(\xv_i, y_i)$被误分类，即$y_i \wv^\top \xv_i \leq 0$，则进行更新$\wv \leftarrow \wv + \eta y_i \xv_i$
4. 转至步骤 2，直至训练集中没有误分类点

输出：$\wv$、感知机模型$f(\xv) = \sgn (\wv^\top \xv)$

如果$(\xv_i, y_i)$被误分类，则更新过后有

$$
\begin{align*}
    \qquad y_i (\wv + \eta y_i \xv_i)^\top \xv_i = y_i \wv^\top \xv_i + \eta \|\xv_i\|_2^2 > y_i \wv^\top \xv_i
\end{align*}
$$

<div class="top-3"></div>

即新$\wv$对$(\xv_i, y_i)$的预测会有所改善，多错几次最终总能预测对
